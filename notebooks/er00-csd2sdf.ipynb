{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c66c05",
   "metadata": {},
   "source": [
    "# Converting  Cambridge Structural Database (CSD) to compressed SDF files\n",
    "\n",
    "Before running this notebook, you'll need to:\n",
    "\n",
    "1. **Obtain a CSD license** - Contact the Cambridge Crystallographic Data Centre (CCDC) to get access to the Cambridge Structural Database.\n",
    "\n",
    "2. **Download the CSD data** - After getting your license, download the database files from the CCDC portal.\n",
    "\n",
    "3. **Setup the environment** - Create a conda environment using the provided environment file:\n",
    "    ```bash\n",
    "    conda env create -f env/csd-api-env.yml\n",
    "    conda activate csd-api-env\n",
    "    ```\n",
    "\n",
    "This notebook is used to transform the CSD stored as sqlite to compressed sdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3e6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import gzip\n",
    "import multiprocessing as mp\n",
    "import shutil\n",
    "import signal\n",
    "import sys\n",
    "import time\n",
    "from functools import partial\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from ccdc.entry import Entry\n",
    "from ccdc.io import EntryReader\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import SaltRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f98f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress2gzip(input_file: str | Path, output_file: str | Path, remove_original: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Compress a file to gzip format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : str or Path\n",
    "        Path to the input file that will be compressed.\n",
    "    output_file : str or Path\n",
    "        Path to the output compressed gzip file.\n",
    "    remove_original : bool, optional\n",
    "        If True, the original file will be removed after compression. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Function compresses a file but doesn't return any value.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If input_file or output_file are not str or Path objects.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Uses gzip and shutil to efficiently compress the input file.\n",
    "    The original file is preserved unless remove_original is set to True.\n",
    "    \"\"\"\n",
    "    # check if inputs are str or Path\n",
    "    if not (isinstance(input_file, (str, Path)) and isinstance(output_file, (str, Path))):\n",
    "        raise TypeError(\"input_file and output_file must be str or Path\")\n",
    "\n",
    "    # convert str to Path if needs be\n",
    "    input_path = Path(input_file) if isinstance(input_file, str) else input_file\n",
    "    output_path = Path(output_file) if isinstance(output_file, str) else output_file\n",
    "\n",
    "    # compress file\n",
    "    with input_path.open(\"rb\") as f_in:\n",
    "        with gzip.open(output_path, \"wb\") as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    # remove original file if requested\n",
    "    if remove_original:\n",
    "        input_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26324342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyArrow schema for error logs\n",
    "error_log_schema = pa.schema(\n",
    "    [\n",
    "        pa.field(\"entry_index\", pa.int32()),\n",
    "        pa.field(\"identifier\", pa.string()),\n",
    "        pa.field(\"error_log\", pa.string()),\n",
    "        pa.field(\"processing_time\", pa.float32()),\n",
    "    ],\n",
    "    metadata={\n",
    "        \"description\": \"Schema for logging errors encountered during CSD to SDF conversion\",\n",
    "        \"entry_index\": \"Index of the CSD entry\",\n",
    "        \"error_log\": \"Error message\",\n",
    "        \"processing_time\": \"Time taken to process the entry\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e002f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 2 min and 15 sec roughly\n",
    "# Answer is : 1394755\n",
    "# counter=0\n",
    "\n",
    "# for _ in csd_reader.entries():\n",
    "#     counter+=1\n",
    "# print(counter)\n",
    "# divmod(counter,10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "884cc66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divmod(1394755, 10_000)  # (139, 755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6589bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeout(max_timeout, default=None):\n",
    "    \"\"\"Timeout decorator, parameter in seconds (supports float values).\"\"\"\n",
    "\n",
    "    def timeout_decorator(func):\n",
    "        \"\"\"Wrap the original function.\"\"\"\n",
    "\n",
    "        @functools.wraps(func)\n",
    "        def func_wrapper(*args, **kwargs):\n",
    "            \"\"\"Timeout using signal with float precision.\"\"\"\n",
    "\n",
    "            class MyTimeoutError(Exception):\n",
    "                pass\n",
    "\n",
    "            def handler(signum, frame):\n",
    "                raise MyTimeoutError\n",
    "\n",
    "            # Set the timeout handler\n",
    "            signal.signal(signal.SIGALRM, handler)\n",
    "            # Use setitimer instead of alarm for float support\n",
    "            signal.setitimer(signal.ITIMER_REAL, max_timeout)\n",
    "            result = default\n",
    "\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "            except MyTimeoutError as exc:\n",
    "                # Handle the timeout\n",
    "                print(str(exc))\n",
    "            finally:\n",
    "                # Cancel the timer\n",
    "                signal.setitimer(signal.ITIMER_REAL, 0)\n",
    "\n",
    "            return result\n",
    "\n",
    "        return func_wrapper\n",
    "\n",
    "    return timeout_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75f65e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeout(0.2, default=(None, \"timeout\"))\n",
    "def process_entry(entry: Entry, salt_remover: SaltRemover.SaltRemover = None) -> tuple[Chem.Mol | None, str]:\n",
    "    \"\"\"\n",
    "    Process a CSD entry into an RDKit molecule.\n",
    "\n",
    "    This function converts a CSD entry to an RDKit molecule and performs salt removal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    entry : Entry\n",
    "        The CSD database entry to process\n",
    "    salt_remover : SaltRemover.SaltRemover, optional\n",
    "        SaltRemover instance to strip salts from molecules. If None, a new instance\n",
    "        will be created.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[Chem.Mol | None, str | None]\n",
    "        A tuple containing:\n",
    "        - RDKit molecule if successfully processed, None otherwise\n",
    "        - Error message if an error occurred, None otherwise\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Error handling includes:\n",
    "    - Capturing stderr during molecule conversion\n",
    "    - Checking for empty molecules\n",
    "    - Handling exceptions during salt removal\n",
    "    \"\"\"\n",
    "\n",
    "    # instantiate variables\n",
    "    rdkit_mol = None\n",
    "    error_log = \"no error\"\n",
    "    if salt_remover is None or not isinstance(salt_remover, SaltRemover.SaltRemover):\n",
    "        salt_remover = SaltRemover.SaltRemover()\n",
    "    mol = entry.molecule\n",
    "\n",
    "    # try to convert the molecule to RDKit format\n",
    "    sio = sys.stderr = StringIO()\n",
    "    mol_block = mol.to_string(\"sdf\")\n",
    "    rdkit_mol = Chem.MolFromMolBlock(mol_block)\n",
    "    error_log = sio.getvalue()\n",
    "\n",
    "    # if error during conversion\n",
    "    if error_log:\n",
    "        return None, error_log\n",
    "\n",
    "    # if empty molecule\n",
    "    if rdkit_mol is None or rdkit_mol.GetNumAtoms() == 0:\n",
    "        return None, \"empty\"\n",
    "\n",
    "    # remove salts\n",
    "    try:\n",
    "        rdkit_mol = salt_remover.StripMol(rdkit_mol, dontRemoveEverything=True)\n",
    "    except Exception as e:\n",
    "        error_log = f\"Error removing salt: {e}\"\n",
    "        return None, error_log\n",
    "\n",
    "    # add entry name to molecule\n",
    "    rdkit_mol.SetProp(\"CSD_Entry_Name\", entry.identifier)\n",
    "\n",
    "    return rdkit_mol, error_log\n",
    "\n",
    "\n",
    "def process_batch(\n",
    "    batch_idx: int, output_dir: Path, error_log_schema: pa.Schema, batch_size: int = 10_000, database_size: int = 1394755\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Process a batch of CSD entries into RDKit molecules and save them as SDF.\n",
    "\n",
    "    This function processes a batch of entries from the CSD database starting at\n",
    "    the specified batch index, converts them to RDKit molecules, removes salts,\n",
    "    and saves them to the output directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_idx : int\n",
    "        Index of the batch to process\n",
    "    output_dir : Path\n",
    "        Directory where output SDF files and error logs will be saved\n",
    "    batch_size : int, optional\n",
    "        Number of entries to process in each batch. Defaults to 10_000.\n",
    "    database_size : int, optional\n",
    "        Total number of entries in the database. Defaults to 1394755.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The index of the processed batch.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Error logs are collected for entries that fail to process and are written\n",
    "    to a separate file for debugging purposes.\n",
    "    \"\"\"\n",
    "\n",
    "    # instantiate variables\n",
    "    error_logs = []\n",
    "    entry_reader = EntryReader(\"CSD\")\n",
    "    salt_remover = SaltRemover.SaltRemover()\n",
    "\n",
    "    # make sure output dir exists\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # calculate the number of entries to process in this batch\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min(start_idx + batch_size, database_size)\n",
    "\n",
    "    # process each entry in the batch\n",
    "    with Chem.SDWriter(output_dir / f\"CSD_batch_{batch_idx:03d}.sdf\") as sdf_writer:\n",
    "        for i in range(start_idx, end_idx):\n",
    "            entry = entry_reader[i]\n",
    "            start_time = time.perf_counter()\n",
    "            rdkit_mol, error_log = process_entry(entry, salt_remover)\n",
    "            if rdkit_mol:\n",
    "                try:\n",
    "                    sdf_writer.write(rdkit_mol)\n",
    "                except Exception as e:\n",
    "                    error_log = f\"Error writing molecule to SDF: {e}\"\n",
    "\n",
    "            error_logs.append(\n",
    "                {\n",
    "                    \"entry_index\": i,\n",
    "                    \"identifier\": entry.identifier,\n",
    "                    \"error_log\": error_log,\n",
    "                    \"processing_time\": time.perf_counter() - start_time,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # write error to files\n",
    "    if error_logs:\n",
    "        error_log_file = output_dir / f\"CSD_batch_{batch_idx:03d}_errors.parquet\"\n",
    "        table = pa.Table.from_pylist(error_logs, schema=error_log_schema)\n",
    "        pq.write_table(table, error_log_file)\n",
    "\n",
    "    # housekeeping\n",
    "    entry_reader.close()\n",
    "\n",
    "    # sdf file compression\n",
    "    compress2gzip(output_dir / f\"CSD_batch_{batch_idx:03d}.sdf\", output_dir / f\"CSD_batch_{batch_idx:03d}.sdf.gz\", remove_original=True)\n",
    "    return batch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f6ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define partial function\n",
    "task_counter = 0\n",
    "partial_process_batch = partial(\n",
    "    process_batch,\n",
    "    output_dir=Path(\"../data/processed/csd_sdf_batches\"),\n",
    "    error_log_schema=error_log_schema,\n",
    "    batch_size=1_000,\n",
    "    database_size=1394755,\n",
    ")\n",
    "# multiprocessing\n",
    "with mp.Pool(processes=mp.cpu_count() - 2) as pool:\n",
    "    results = pool.map(partial_process_batch, range(1400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "527a1895",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path(\"../data/processed/csd_sdf_batches/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc69c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx_set = set()\n",
    "for file in results_dir.glob(\"*.sdf.gz\"):\n",
    "    # retrieve index from filename\n",
    "    batch_idx = int(file.stem.replace(\".sdf\", \"\").split(\"_\")[-1])\n",
    "    batch_idx_set.add(batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "558f2cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_batches = set(range(1400)) - batch_idx_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4678138c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8547f498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for missing_idx in missing_batches:\n",
    "    process_batch(\n",
    "        missing_idx,\n",
    "        output_dir=Path(\"../data/processed/csd_sdf_batches\"),\n",
    "        error_log_schema=error_log_schema,\n",
    "        batch_size=1_000,\n",
    "        database_size=1394755,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csd-api-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
